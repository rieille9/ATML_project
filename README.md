# ğŸ² Snakes and Ladders â€“ Reinforcement Learning Project

*Advanced Topics in Machine Learning â€“ Spring 2025*  
*MSc in Business Analytics â€“ University of Geneva*  
Grade: **21.5 / 20** (including bonus task)

---

## ğŸ“Œ Overview

This project implements a **custom reinforcement learning environment** inspired by the board game *Snakes and Ladders*, where a single agent aims to reach the goal square while maximizing total reward.

Developed as part of a master-level course, the project models the game as a **Markov Decision Process (MDP)** and solves it using:
- **Dynamic Programming (DP)**: value iteration & policy evaluation  
- **Monte Carlo Simulation**  
- Bonus task: modifying the environment with an extra snake (28 â†’ 14) and analyzing its impact

---

## ğŸ§  Problem Summary

- Board of 30 squares
- Player starts at square 1 with 0 points
- Each action has a cost and results in movement:
  - Pay 3 pts â†’ move 1 square
  - Pay 1 pt â†’ roll `{1, 2, 3}`
  - Pay 2 pts â†’ roll `{4, 5, 6, 7}`
- Reaching square 30 â†’ +10 pts, game ends  
- Overshooting â†’ reset to square 1 with penalty  
- Snakes: 17â†’4, 20â†’6, 24â†’16  
- Ladders: 5â†’7, 9â†’27, 11â†’29  
- Discount factor: Î³ = 1

---

## ğŸš€ Key Features

- ğŸ” **Game Environment Class**  
  - `.step(action)` â†’ returns next state & reward  
  - `.reset()` â†’ resets game

- ğŸ“Š **Policy Evaluation via DP**  
  - Policies tested:
    - â€œStepâ€ (always move 1 step)
    - â€œRollâ€ (always roll small dice)
    - â€œRandomâ€ (mixed strategy)
  
- ğŸ§­ **Optimal Policy Search**  
  - Value iteration for state-value and action-value functions

- ğŸ² **Monte Carlo Simulation**  
  - Estimate value of initial state under each policy

- âœ… **Bonus Task**  
  - Added snake 28â†’14  
  - Adjusted algorithms and commented on policy changes

